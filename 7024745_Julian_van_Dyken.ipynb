{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f05ae28c",
   "metadata": {},
   "source": [
    "# Task 1: Describe the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c812c",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "Goal: Understand the structure and basic properties of the dataset using Python (NumPy, pandas, Matplotlib/Seaborn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f466a036",
   "metadata": {},
   "source": [
    "1) Read the CSV file with pandas.read_csv and parse the datetime\n",
    "column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "day = pd.read_csv(\"day.csv\")\n",
    "hour = pd.read_csv(\"hour.csv\")\n",
    "\n",
    "day[\"dteday\"] = pd.to_datetime(day[\"dteday\"])\n",
    "hour[\"dteday\"] = pd.to_datetime(hour[\"dteday\"])\n",
    "\n",
    "hour[\"datetime\"] = hour[\"dteday\"] + pd.to_timedelta(hour[\"hr\"], unit=\"h\")\n",
    "\n",
    "df_pre = pd.merge(\n",
    "    hour,\n",
    "    day,\n",
    "    on=\"dteday\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_hour\", \"_day\")\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"datetime\": df_pre[\"datetime\"],\n",
    "        \"target\": df_pre[\"cnt_hour\"],\n",
    "        \"weather\": df_pre[\"weathersit_hour\"],\n",
    "        \"temp\": df_pre[\"temp_hour\"],\n",
    "        \"humidity\": df_pre[\"hum_hour\"],\n",
    "        \"windspeed\": df_pre[\"windspeed_hour\"],\n",
    "        \"season\": df_pre[\"season_day\"],\n",
    "        \"day_of_week\": df_pre[\"weekday_day\"],\n",
    "        \"is_holiday\": df_pre[\"holiday_day\"],\n",
    "        \"is_workingday\": df_pre[\"workingday_day\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316f2d2",
   "metadata": {},
   "source": [
    "2. Report:\n",
    "- Number of rows and columns.\n",
    "- Time range covered by the data.\n",
    "- Target variable and list of feature variables (names and data types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c977968",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataframe_report(df: pd.DataFrame, target_col: str, time_col: str):\n",
    "    print(\"=== DATAFRAME REPORT ===\\n\")\n",
    "\n",
    "    # Rows & Columns\n",
    "    n_rows, n_cols = df.shape\n",
    "    print(f\"Number of rows: {n_rows}\")\n",
    "    print(f\"Number of columns: {n_cols}\\n\")\n",
    "\n",
    "    # Time range\n",
    "    df[time_col] = pd.to_datetime(df[time_col], errors=\"coerce\")\n",
    "    start_date = df[time_col].min()\n",
    "    end_date = df[time_col].max()\n",
    "    print(f\"Time range covered: {start_date} → {end_date}\\n\")\n",
    "\n",
    "    # Target variable\n",
    "    print(\"Target variable:\")\n",
    "    print(f\"  - {target_col} ({df[target_col].dtype})\\n\")\n",
    "\n",
    "    # Feature variables\n",
    "    feature_cols = [col for col in df.columns if col not in [target_col, time_col]]\n",
    "    print(\"Feature variables:\")\n",
    "    for col in feature_cols:\n",
    "        print(f\"  - {col}: {df[col].dtype}\")\n",
    "\n",
    "# Beispiel-Aufruf\n",
    "dataframe_report(\n",
    "    df=df,\n",
    "    target_col=\"target\",\n",
    "    time_col=\"datetime\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07a954",
   "metadata": {},
   "source": [
    "3. Create a variable description table (see above for reference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c769fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variable_description_table(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    time_col: str\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col == time_col:\n",
    "            role = \"time\"\n",
    "        elif col == target_col:\n",
    "            role = \"target\"\n",
    "        else:\n",
    "            role = \"feature\"\n",
    "\n",
    "        rows.append({\n",
    "            \"variable_name\": col,\n",
    "            \"role\": role,\n",
    "            \"data_type\": df[col].dtype.name,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Example usage\n",
    "var_table = create_variable_description_table(\n",
    "    df=df,\n",
    "    target_col=\"target\",\n",
    "    time_col=\"datetime\"\n",
    ")\n",
    "\n",
    "var_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2964683",
   "metadata": {},
   "source": [
    "4. Check for:\n",
    "- Missing values per column.\n",
    "- Duplicated rows (if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584188ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of duplicate rows: {df.duplicated().sum()}')\n",
    "print(f'Number of missing values: {df.isna().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618ed61",
   "metadata": {},
   "source": [
    "## Descriptive statistics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b3f2b",
   "metadata": {},
   "source": [
    "For numeric variables: calculate mean, standard deviation, minimum, maximum, and quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"target\",\"temp\",\"humidity\",\"windspeed\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fe33e4",
   "metadata": {},
   "source": [
    "For categorical variables: show frequency tables or bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c26e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"weather\", \"season\", \"is_holiday\", \"is_workingday\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n=== {col.upper()} ===\")\n",
    "    print(df[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf241a",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ddfc1",
   "metadata": {},
   "source": [
    "Plot the time series of total bike demand (count) over the full\n",
    "period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df[\"datetime\"], df[\"target\"])\n",
    "plt.title(\"total bike demand (count) over the full period\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac01fb7",
   "metadata": {},
   "source": [
    "Plot distributions of key numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"temp\", \"humidity\", \"windspeed\"]].hist(\n",
    "    bins=40,\n",
    "    layout=(3, 1),\n",
    "    figsize=(10, 12)\n",
    "    \n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65ca6b1",
   "metadata": {},
   "source": [
    "Plot aggregated demand by season, day of week or hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8bd230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cpy = df.copy()\n",
    "\n",
    "# Per Season\n",
    "season_demand = df.groupby(\"season\")[\"target\"].mean()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(season_demand.index, season_demand.values, color=\"skyblue\")\n",
    "plt.xlabel(\"Season\")\n",
    "plt.ylabel(\"Average Bike Demand\")\n",
    "plt.title(\"Average Bike Demand by Season\")\n",
    "plt.xticks(season_demand.index, [\"Spring\", \"Summer\", \"Fall\", \"Winter\"])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per Day of Week\n",
    "df_cpy[\"weekday\"] = df[\"datetime\"].dt.dayofweek  # 0 = Montag, 6 = Sonntag\n",
    "weekday_demand = df_cpy.groupby(\"weekday\")[\"target\"].mean()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(weekday_demand.index, weekday_demand.values, color=\"orange\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Average Bike Demand\")\n",
    "plt.title(\"Average Bike Demand by Day of Week\")\n",
    "plt.xticks(weekday_demand.index, [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per Hour of Day\n",
    "df_cpy[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "hourly_demand = df_cpy.groupby(\"hour\")[\"target\"].mean() \n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(hourly_demand.index, hourly_demand.values, color=\"green\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Average Bike Demand\")\n",
    "plt.title(\"Average Bike Demand by Hour of Day\")\n",
    "plt.xticks(range(0, 24))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f765f9",
   "metadata": {},
   "source": [
    "### Description\n",
    "Demand shows clear seasonal and daily patterns.\n",
    "Fall has the highest demand, while spring has the lowest demand.\n",
    "Demand is very similar across all days of the week, with no strong differences.\n",
    "Demand is lowest at night and rises to a first peak around 8 o’clock, decreasing slightly during midday, and reaching a second peak around 17 o’clock.\n",
    "After this second peak, demand drops sharply until late in the evening."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea441ec",
   "metadata": {},
   "source": [
    "# Task 2: Predict Demand from Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faab141",
   "metadata": {},
   "source": [
    "## Supervised Regression Setup\n",
    "Goal: Build a supervised regression model that predicts bike demand\n",
    "count from given conditions (features such as weather, temperature,\n",
    "time of day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db568f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "#Features und Target definieren\n",
    "features = [\"season\", \"is_holiday\", \"is_workingday\", \"weather\", \"temp\", \"humidity\", \"windspeed\"]\n",
    "target = \"target\"\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "#Trainings-, Validation- and Test-Splitting (70%/10%/20%)\n",
    "X_train_and_val, X_test, y_train_and_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_and_val, y_train_and_val, test_size=0.125, random_state=42)  # 0.125*0.8 ≈ 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e1671",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#Preprocessing\n",
    "categorical_features = [\"season\", \"is_holiday\", \"is_workingday\", \"weather\"]\n",
    "numeric_features = [\"temp\", \"humidity\", \"windspeed\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features) # drop for avoiding dummy variable trap\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "\n",
    "# Building model\n",
    "\n",
    "shape_input = X_train_proc.shape[1]\n",
    "model = Sequential([\n",
    "    layers.Input(shape=(shape_input,)),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "history = model.fit(\n",
    "    X_train_proc,\n",
    "    y_train,\n",
    "    validation_data = (X_val_proc, y_val), # TODO: NORM!!!\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_test_pred = model.predict(X_test_proc).flatten()\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "print(\"Test RMSE:\", rmse_test)\n",
    "print(\"Test MAE:\", mae_test)\n",
    "print(\"Test R2:\", r2_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    \"r--\"\n",
    ")\n",
    "plt.xlabel(\"Actual Count\")\n",
    "plt.ylabel(\"Predicted Count\")\n",
    "plt.title(\"Predicted vs Actual Bike Demand\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d4353",
   "metadata": {},
   "source": [
    "## User Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c39da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bike_demand(\n",
    "    season,\n",
    "    is_holiday,\n",
    "    is_workingday,\n",
    "    weather,\n",
    "    temp,\n",
    "    humidity,\n",
    "    windspeed\n",
    "):\n",
    "    \"\"\"\n",
    "    Predict bike demand for a single scenario.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create input DataFrame (must match training features exactly)\n",
    "    input_df = pd.DataFrame([{\n",
    "        \"season\": season,\n",
    "        \"is_holiday\": is_holiday,\n",
    "        \"is_workingday\": is_workingday,\n",
    "        \"weather\": weather,\n",
    "        \"temp\": temp,\n",
    "        \"humidity\": humidity,\n",
    "        \"windspeed\": windspeed\n",
    "    }])\n",
    "\n",
    "    # Apply preprocessing\n",
    "    X_proc = preprocessor.transform(input_df)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(X_proc, verbose=0)\n",
    "\n",
    "    return float(prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc51ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = predict_bike_demand(\n",
    "    season=3,        # fall\n",
    "    is_holiday=0,\n",
    "    is_workingday=1,\n",
    "    weather=1,       # clear\n",
    "    temp=18,\n",
    "    humidity=55,\n",
    "    windspeed=10\n",
    ")\n",
    "print(\"Prediction 1:\", pred1)\n",
    "\n",
    "pred2 = predict_bike_demand(\n",
    "    season=4,        # winter\n",
    "    is_holiday=0,\n",
    "    is_workingday=0,\n",
    "    weather=3,       # rain/snow\n",
    "    temp=2,\n",
    "    humidity=85,\n",
    "    windspeed=20\n",
    ")\n",
    "print(\"Prediction 2:\", pred2)\n",
    "\n",
    "pred3 = predict_bike_demand(\n",
    "    season=2,        # summer\n",
    "    is_holiday=0,\n",
    "    is_workingday=1,\n",
    "    weather=1,       # clear\n",
    "    temp=26,\n",
    "    humidity=40,\n",
    "    windspeed=7\n",
    ")\n",
    "print(\"Prediction 3:\", pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4966b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Feature Engineering\n",
    "# ===============================\n",
    "X_feat = np.concatenate([\n",
    "    np.arange(len(df)).reshape(-1, 1),  # time trend\n",
    "    df[\"datetime\"].dt.dayofweek.values.reshape(-1, 1),  # day of week (0–6)\n",
    "    df[\"datetime\"].dt.month.values.reshape(-1, 1),  # month (1–12)\n",
    "    df[\"datetime\"].dt.dayofyear.values.reshape(-1, 1),  # day of year (1–365)\n",
    "    (df[\"datetime\"].dt.dayofweek >= 5).astype(int).values.reshape(-1, 1)  # weekend flag\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6798feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Sliding Windows\n",
    "# ===============================\n",
    "\n",
    "WINDOW = 30\n",
    "def make_windows(X, y, w):\n",
    "    return (\n",
    "        np.array([X[i:i + w] for i in range(len(X) - w)]),\n",
    "        np.array([y[i + w] for i in range(len(y) - w)])\n",
    "    )\n",
    "X_window, y_window = make_windows(X=X_feat, y=y, w=WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afad5dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Train / Validation / Test Split\n",
    "# ===============================\n",
    "\n",
    "n = len(X_window)\n",
    "train_percent = 0.7\n",
    "val_percent = 0.15\n",
    "\n",
    "train_end = int(train_percent * n)\n",
    "val_end   = int((train_percent + val_percent) * n)\n",
    "\n",
    "X_train = X_window[:train_end]\n",
    "y_train = y_window[:train_end]\n",
    "\n",
    "X_val   = X_window[train_end:val_end]\n",
    "y_val   = y_window[train_end:val_end]\n",
    "\n",
    "X_test  = X_window[val_end:]\n",
    "y_test  = y_window[val_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Normalization\n",
    "# ===============================\n",
    "\n",
    "# Normalize inputs using training data only\n",
    "X_mean = X_train.mean((0, 1), keepdims=True)\n",
    "X_std = X_train.std((0, 1), keepdims=True) + 1e-8\n",
    "\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_val = (X_val - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "\n",
    "# Normalize target values\n",
    "y_mean = y_train.mean()\n",
    "y_std = y_train.std() + 1e-8\n",
    "\n",
    "y_train = (y_train - y_mean) / y_std\n",
    "y_val = (y_val - y_mean) / y_std\n",
    "y_test = (y_test - y_mean) / y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec88cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# ===============================\n",
    "# Model\n",
    "# ===============================\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input((WINDOW, X_train.shape[2])),\n",
    "    keras.layers.LSTM(64),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Evaluation & Visualization\n",
    "# ===============================\n",
    "\n",
    "y_pred_norm = model.predict(X_test)\n",
    "y_pred = y_pred_norm * y_std + y_mean\n",
    "\n",
    "y_true = y_test * y_std + y_mean\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mae_test = mean_absolute_error(y_true, y_pred)\n",
    "r2_test = r2_score(y_true, y_pred)\n",
    "print(\"Test RMSE:\", rmse_test)\n",
    "print(\"Test MAE:\", mae_test)\n",
    "print(\"Test R2:\", r2_test)\n",
    "\n",
    "y_naive = y_true[:-1]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(y_true, label=\"True\", color=\"black\", linestyle=\"-\")\n",
    "plt.plot(y_pred, label=\"LSTM Prediction\", color=\"blue\", linestyle=\"-\", alpha=0.7)\n",
    "plt.plot(range(1, len(y_true)), y_naive, label=\"Naive Forecast\", color=\"red\", linestyle=\"--\", alpha=0.4)\n",
    "# plt.plot(y_naive, label=\"Naive Forecast\", color=\"red\", alpha=0.7)\n",
    "plt.title(\"Demand Forecasting: True vs Predicted vs Baseline\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Demand\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85ded1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'demand'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/data/python/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'demand'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Vollständige Historie + Forecast\u001b[39;00m\n\u001b[32m     45\u001b[39m plt.figure(figsize=(\u001b[32m15\u001b[39m,\u001b[32m5\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m plt.plot(df[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m], \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdemand\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, label=\u001b[33m\"\u001b[39m\u001b[33mTrue Demand\u001b[39m\u001b[33m\"\u001b[39m, color=\u001b[33m\"\u001b[39m\u001b[33mblack\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m forecast_dates = pd.date_range(start=df[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m].iloc[-\u001b[32m1\u001b[39m]+pd.Timedelta(hours=\u001b[32m1\u001b[39m), periods=forecast_horizon, freq=\u001b[33m'\u001b[39m\u001b[33mH\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     48\u001b[39m plt.plot(forecast_dates, multi_step_preds, label=\u001b[33m\"\u001b[39m\u001b[33m30-step Forecast\u001b[39m\u001b[33m\"\u001b[39m, color=\u001b[33m\"\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m\"\u001b[39m, linestyle=\u001b[33m\"\u001b[39m\u001b[33m--\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/data/python/lib/python3.13/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/data/python/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'demand'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dates = df['datetime']\n",
    "\n",
    "forecast_horizon = 30\n",
    "window = WINDOW  # wie beim Training\n",
    "\n",
    "# letzte bekannten Inputs (die letzten WINDOW Zeitschritte)\n",
    "last_X = X_feat[-window:].copy()  # Shape: (WINDOW, n_features)\n",
    "\n",
    "multi_step_preds = []\n",
    "\n",
    "for step in range(forecast_horizon):\n",
    "    # LSTM erwartet Shape (1, WINDOW, features)\n",
    "    input_X = last_X.reshape(1, window, last_X.shape[1])\n",
    "    \n",
    "    # Vorhersage\n",
    "    pred_norm = model.predict(input_X, verbose=0)\n",
    "    \n",
    "    # Rückskalierung auf Originalwerte\n",
    "    pred = pred_norm[0,0] * y_std + y_mean\n",
    "    multi_step_preds.append(pred)\n",
    "    \n",
    "    # Update last_X für nächsten Schritt\n",
    "    # Neue Features generieren\n",
    "    new_t = last_X[-1, 0] + 1\n",
    "    new_datetime = dates.iloc[-1] + pd.Timedelta(hours=step+1)\n",
    "    new_features = np.array([\n",
    "        new_t,\n",
    "        new_datetime.dayofweek,\n",
    "        new_datetime.month,\n",
    "        new_datetime.dayofyear,\n",
    "        int(new_datetime.dayofweek >= 5)\n",
    "    ])\n",
    "    \n",
    "    # Normierung wie beim Training (X_mean/X_std)\n",
    "    new_features_norm = (new_features - X_mean[0,0]) / X_std[0,0]  # ggf. alle Features normalisieren\n",
    "    \n",
    "    # append neuen Schritt und verschiebe Fenster\n",
    "    last_X = np.vstack([last_X[1:], new_features])\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Vollständige Historie + Forecast\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(df['datetime'], df['target'], label=\"True Demand\", color=\"black\")\n",
    "forecast_dates = pd.date_range(start=df['datetime'].iloc[-1]+pd.Timedelta(hours=1), periods=forecast_horizon, freq='H')\n",
    "plt.plot(forecast_dates, multi_step_preds, label=\"30-step Forecast\", color=\"blue\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Demand\")\n",
    "plt.title(\"Multi-step 30-Day Forecast\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
